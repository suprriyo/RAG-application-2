# RAG-Based Question Answering System

A Retrieval-Augmented Generation (RAG) system for educational content that allows students to upload PDF textbooks and ask questions about their content.

**ğŸŒ Live Demo:** [Deploy to Streamlit Cloud](https://share.streamlit.io)

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io)

## Features

-  **PDF Upload**: Upload educational PDFs (textbooks, papers, etc.)
-  **Interactive Chat**: Ask questions and get answers based on uploaded content
-  **Source Citations**: View which parts of the documents were used to generate answers
-  **Multi-Document Support**: Upload multiple PDFs and query across all documents
-  **Performance Metrics**: See answer generation time
-  **Document Management**: View uploaded documents and manage the database

## Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository-url>
cd rag-qa-system

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copy the example environment file
cp .env.example .env

# Edit .env and add your API keys
# Required: OPENAI_API_KEY
# Optional: ANTHROPIC_API_KEY, HUGGINGFACE_API_KEY
```

### 3. Run the Application

#### Web Interface (Streamlit)

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

#### Command Line Interface (CLI)

```bash
# Upload a document
python main.py upload path/to/textbook.pdf

# Ask a question
python main.py ask "What is Newton's first law?"

# List uploaded documents
python main.py list

# Reset database
python main.py reset
```

## Usage Guide

### Uploading Documents

1. Go to the "Upload Documents" tab
2. Click "Choose a PDF file" and select your document
3. Click "Process Document"
4. Wait for processing to complete (you'll see progress updates)

### Asking Questions

1. Go to the "Chat" tab
2. Type your question in the chat input
3. Press Enter or click Send
4. View the answer along with source citations
5. Click "View Sources" to see which parts of the document were used

### Managing Documents

- View uploaded documents in the sidebar
- See document statistics (chunks, size, upload time)
- Clear conversation history with "Clear Conversation" button
- Reset entire database with "Reset Database" button

## Configuration

Edit `config.yaml` to customize:

- **Embedding Model**: Choose between OpenAI or HuggingFace embeddings
- **LLM Provider**: Use OpenAI GPT or Anthropic Claude
- **Chunk Size**: Adjust text chunking parameters
- **Retrieval Settings**: Configure how many relevant chunks to retrieve

Example configuration:

```yaml
embedding:
  provider: "openai"
  model: "text-embedding-ada-002"

llm:
  provider: "openai"
  model: "gpt-3.5-turbo"
  temperature: 0.7
  max_tokens: 500

chunking:
  chunk_size: 1000
  chunk_overlap: 200

retrieval:
  top_k: 4
  score_threshold: 0.7
```

## Deployment to Streamlit Cloud

### Prerequisites

- GitHub account
- Streamlit Cloud account (free at share.streamlit.io)

### Steps

1. **Push to GitHub**
   ```bash
   git init
   git add .
   git commit -m "Initial commit"
   git remote add origin <your-github-repo-url>
   git push -u origin main
   ```

2. **Deploy on Streamlit Cloud**
   - Go to [share.streamlit.io](https://share.streamlit.io)
   - Click "New app"
   - Select your repository, branch, and `app.py`
   - Click "Deploy"

3. **Configure Secrets**
   - In Streamlit Cloud dashboard, go to your app settings
   - Click "Secrets"
   - Add your API keys:
     ```toml
     OPENAI_API_KEY = "your_key_here"
     ```

4. **Share Your App**
   - Your app will be available at: `https://share.streamlit.io/[username]/[repo]/[branch]/app.py`
   - Share this URL with users

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Student   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Streamlit Web Interface         â”‚
â”‚  - Upload PDFs                      â”‚
â”‚  - Chat Interface                   â”‚
â”‚  - Document Management              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Engine (Orchestrator)         â”‚
â”‚  - Document Processing              â”‚
â”‚  - Query Processing                 â”‚
â”‚  - Session Management               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Document   â”‚   â”‚     Query       â”‚
â”‚  Processing  â”‚   â”‚   Processing    â”‚
â”‚   Pipeline   â”‚   â”‚    Pipeline     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LangChain Layer                â”‚
â”‚  - PDF Loaders                      â”‚
â”‚  - Text Splitters                   â”‚
â”‚  - Embeddings                       â”‚
â”‚  - Vector Stores (ChromaDB)         â”‚
â”‚  - LLM Integration                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Technology Stack

- **Framework**: LangChain (Python)
- **Vector Database**: ChromaDB
- **Embeddings**: OpenAI / HuggingFace
- **LLM**: OpenAI GPT / Anthropic Claude
- **PDF Processing**: PyPDF2
- **Web Interface**: Streamlit
- **CLI**: Click

## Troubleshooting

### API Key Errors

If you see "Missing required API key" errors:
- Check that your `.env` file exists and contains valid API keys
- Ensure the `.env` file is in the project root directory
- Restart the application after updating `.env`

### PDF Processing Errors

If PDF upload fails:
- Ensure the PDF is not corrupted
- Check that the file size is under 100MB
- Verify the PDF contains extractable text (not just images)

### Database Issues

If you encounter database errors:
- Try resetting the database using the "Reset Database" button
- Delete the `data/chroma_db` directory and restart the app
- Check that you have write permissions in the project directory

## License

MIT License

## Support

For issues and questions, please open an issue on GitHub.


---

## ğŸš€ Deployment to Streamlit Cloud

### Quick Deploy

1. **Fork/Clone this repository**
2. **Push to your GitHub**
3. **Go to** [share.streamlit.io](https://share.streamlit.io)
4. **Click** "New app" and select your repo
5. **Add secrets:**
   ```toml
   OPENAI_API_KEY = "your-key-here"
   ```
6. **Deploy!**

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.

### âš ï¸ Important Note

Streamlit Cloud has ephemeral storage. Uploaded documents are temporary and will be lost when the app restarts. For production use, consider:
- Pinecone (free tier available)
- AWS S3 for persistent storage
- PostgreSQL for user management

---

## ğŸ“ Project Structure

```
rag-qa-system/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ src/                        # Core RAG components
â”‚   â”œâ”€â”€ rag_engine.py          # Main orchestrator
â”‚   â”œâ”€â”€ pdf_loader.py          # PDF processing
â”‚   â”œâ”€â”€ text_chunker.py        # Text splitting
â”‚   â”œâ”€â”€ embedding_service.py   # Embeddings generation
â”‚   â”œâ”€â”€ vector_store_manager.py # ChromaDB management
â”‚   â”œâ”€â”€ query_processor.py     # Query handling
â”‚   â”œâ”€â”€ answer_generator.py    # LLM answer generation
â”‚   â””â”€â”€ config.py              # Configuration management
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ config.toml            # Streamlit configuration
â”‚   â””â”€â”€ secrets.toml.example   # Secrets template
â”œâ”€â”€ config.yaml                # App configuration
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ packages.txt              # System dependencies
â”œâ”€â”€ .gitignore                # Git ignore rules
â”œâ”€â”€ DEPLOYMENT.md             # Deployment guide
â””â”€â”€ README.md                 # This file
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io)
- Powered by [LangChain](https://langchain.com)
- Vector storage by [ChromaDB](https://www.trychroma.com)
- LLM by [OpenAI](https://openai.com)

---

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Made with â¤ï¸ for education**
